{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib as mlt\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.signal import butter, lfilter, filtfilt,argrelextrema\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "import copy\n",
    "import math\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier,LocalOutlierFactor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.rcParams[\"figure.figsize\"]=(20,5)\n",
    "plt.rcParams[\"figure.dpi\"]=100\n",
    "plt.rcParams[\"lines.linewidth\"]=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df,cutoff=0.4,order=10,column=\"Accelerometer_r\"):\n",
    "    data=LowPass.low_pass_filter(df,column,fs,cutoff,order)\n",
    "    indexes=argrelextrema(data[column+\"_lowpass\"].values,np.greater)\n",
    "    peeks=data.iloc[indexes]\n",
    "    fig,ax=plt.subplots()\n",
    "    plt.plot(df[f\"{column}_lowpass\"])\n",
    "    plt.plot(peeks[f\"{column}_lowpass\"],\"o\",color=\"red\")\n",
    "    ax.set_ylabel(f\"{column}_lowpass\")\n",
    "    exercise=df[\"Label\"].iloc[0].title()\n",
    "    category=df[\"Category\"].iloc[0].title()\n",
    "    plt.title(f\"{category} {exercise}: {len(peeks)} Reps\")\n",
    "    plt.show()\n",
    "    return len(peeks)\n",
    "\n",
    "# This class performs a Fourier transformation on the data to find frequencies that occur\n",
    "# often and filter noise.\n",
    "class FourierTransformation:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.temp_list = []\n",
    "        self.freqs = None\n",
    "\n",
    "    # Find the amplitudes of the different frequencies using a fast fourier transformation. Here,\n",
    "    # the sampling rate expresses\n",
    "    # the number of samples per second (i.e. Frequency is Hertz of the dataset).\n",
    "    \n",
    "    def find_fft_transformation(self, data):\n",
    "        # Create the transformation, this includes the amplitudes of both the real\n",
    "        # and imaginary part.\n",
    "        # print(data.shape)\n",
    "        transformation = np.fft.rfft(data, len(data))\n",
    "        # real\n",
    "        real_ampl = transformation.real\n",
    "        # max\n",
    "        max_freq = self.freqs[np.argmax(real_ampl[0:len(real_ampl)])]\n",
    "        # weigthed\n",
    "        freq_weigthed = float(np.sum(self.freqs * real_ampl)) / np.sum(real_ampl)\n",
    "\n",
    "        # pse\n",
    "\n",
    "        PSD = np.divide(np.square(real_ampl), float(len(real_ampl)))\n",
    "        PSD_pdf = np.divide(PSD, np.sum(PSD))\n",
    "\n",
    "        # Make sure there are no zeros.\n",
    "        if np.count_nonzero(PSD_pdf) == PSD_pdf.size:\n",
    "            pse = -np.sum(np.log(PSD_pdf) * PSD_pdf)\n",
    "        else:\n",
    "            pse = 0\n",
    "\n",
    "        real_ampl = np.insert(real_ampl, 0, max_freq)\n",
    "        real_ampl = np.insert(real_ampl, 0, freq_weigthed)\n",
    "        row = np.insert(real_ampl, 0, pse)\n",
    "\n",
    "        self.temp_list.append(row)\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # Get frequencies over a certain window.\n",
    "    def abstract_frequency(self, data_table, columns, window_size, sampling_rate):\n",
    "        self.freqs = (sampling_rate * np.fft.rfftfreq(int(window_size))).round(3)\n",
    "\n",
    "        for col in columns:\n",
    "            collist = []\n",
    "            # prepare column names\n",
    "            collist.append(col + '_max_freq')\n",
    "            collist.append(col + '_freq_weighted')\n",
    "            collist.append(col + '_pse')\n",
    "            \n",
    "            collist = collist + [col + '_freq_' +\n",
    "                    str(freq) + '_Hz_ws_' + str(window_size) for freq in self.freqs]\n",
    "           \n",
    "            # rolling statistics to calculate frequencies, per window size. \n",
    "            # Pandas Rolling method can only return one aggregation value. \n",
    "            # Therefore values are not returned but stored in temp class variable 'temp_list'.\n",
    "\n",
    "            # note to self! Rolling window_size would be nicer and more logical! In older version windowsize is actually 41. (ws + 1)\n",
    "            data_table[col].rolling(\n",
    "                window_size + 1).apply(self.find_fft_transformation)\n",
    "\n",
    "            # Pad the missing rows with nans\n",
    "            frequencies = np.pad(np.array(self.temp_list), ((window_size, 0), (0, 0)),\n",
    "                        'constant', constant_values=np.nan)\n",
    "            # add new freq columns to frame\n",
    "            \n",
    "            data_table[collist] = pd.DataFrame(frequencies, index=data_table.index)\n",
    "\n",
    "            # reset temp-storage array\n",
    "            del self.temp_list[:]\n",
    "            \n",
    "\n",
    "        \n",
    "        return data_table\n",
    "\n",
    "class ClassificationAlgorithms:\n",
    "\n",
    "    # Forward selection for classification which selects a pre-defined number of features (max_features)\n",
    "    # that show the best accuracy. We assume a decision tree learning for this purpose, but\n",
    "    # this can easily be changed. It return the best features.\n",
    "    def forward_selection(self, max_features, X_train, y_train):\n",
    "        # Start with no features.\n",
    "        ordered_features = []\n",
    "        ordered_scores = []\n",
    "        selected_features = []\n",
    "        ca = ClassificationAlgorithms()\n",
    "        prev_best_perf = 0\n",
    "\n",
    "        # Select the appropriate number of features.\n",
    "        for i in range(0, max_features):\n",
    "            print(i)\n",
    "\n",
    "            # Determine the features left to select.\n",
    "            features_left = list(set(X_train.columns) - set(selected_features))\n",
    "            best_perf = 0\n",
    "            best_attribute = \"\"\n",
    "\n",
    "            # For all features we can still select...\n",
    "            for f in features_left:\n",
    "                temp_selected_features = copy.deepcopy(selected_features)\n",
    "                temp_selected_features.append(f)\n",
    "\n",
    "                # Determine the accuracy of a decision tree learner if we were to add\n",
    "                # the feature.\n",
    "                (\n",
    "                    pred_y_train,\n",
    "                    pred_y_test,\n",
    "                    prob_training_y,\n",
    "                    prob_test_y,\n",
    "                ) = ca.decision_tree(\n",
    "                    X_train[temp_selected_features],\n",
    "                    y_train,\n",
    "                    X_train[temp_selected_features],\n",
    "                )\n",
    "                perf = accuracy_score(y_train, pred_y_train)\n",
    "\n",
    "                # If the performance is better than what we have seen so far (we aim for high accuracy)\n",
    "                # we set the current feature to the best feature and the same for the best performance.\n",
    "                if perf > best_perf:\n",
    "                    best_perf = perf\n",
    "                    best_feature = f\n",
    "            # We select the feature with the best performance.\n",
    "            selected_features.append(best_feature)\n",
    "            prev_best_perf = best_perf\n",
    "            ordered_features.append(best_feature)\n",
    "            ordered_scores.append(best_perf)\n",
    "        return selected_features, ordered_features, ordered_scores\n",
    "\n",
    "    # Apply a neural network for classification upon the training data (with the specified composition of\n",
    "    # hidden layers and number of iterations), and use the created network to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def feedforward_neural_network(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        hidden_layer_sizes=(100,),\n",
    "        max_iter=2000,\n",
    "        activation=\"logistic\",\n",
    "        alpha=0.0001,\n",
    "        learning_rate=\"adaptive\",\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"hidden_layer_sizes\": [\n",
    "                        (5,),\n",
    "                        (10,),\n",
    "                        (25,),\n",
    "                        (100,),\n",
    "                        (\n",
    "                            100,\n",
    "                            5,\n",
    "                        ),\n",
    "                        (\n",
    "                            100,\n",
    "                            10,\n",
    "                        ),\n",
    "                    ],\n",
    "                    \"activation\": [activation],\n",
    "                    \"learning_rate\": [learning_rate],\n",
    "                    \"max_iter\": [1000, 2000],\n",
    "                    \"alpha\": [alpha],\n",
    "                }\n",
    "            ]\n",
    "            nn = GridSearchCV(\n",
    "                MLPClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            # Create the model\n",
    "            nn = MLPClassifier(\n",
    "                hidden_layer_sizes=hidden_layer_sizes,\n",
    "                activation=activation,\n",
    "                max_iter=max_iter,\n",
    "                learning_rate=learning_rate,\n",
    "                alpha=alpha,\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "        nn.fit(\n",
    "            train_X,\n",
    "            train_y.values.ravel(),\n",
    "        )\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(nn.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            nn = nn.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = nn.predict_proba(train_X)\n",
    "        pred_prob_test_y = nn.predict_proba(test_X)\n",
    "        pred_training_y = nn.predict(train_X)\n",
    "        pred_test_y = nn.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=nn.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=nn.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a support vector machine for classification upon the training data (with the specified value for\n",
    "    # C, epsilon and the kernel function), and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def support_vector_machine_with_kernel(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        kernel=\"rbf\",\n",
    "        C=1,\n",
    "        gamma=1e-3,\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\"kernel\": [\"rbf\", \"poly\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100]}\n",
    "            ]\n",
    "            svm = GridSearchCV(\n",
    "                SVC(probability=True), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            svm = SVC(\n",
    "                C=C, kernel=kernel, gamma=gamma, probability=True, cache_size=7000\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "        svm.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(svm.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            svm = svm.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = svm.predict_proba(train_X)\n",
    "        pred_prob_test_y = svm.predict_proba(test_X)\n",
    "        pred_training_y = svm.predict(train_X)\n",
    "        pred_test_y = svm.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=svm.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=svm.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a support vector machine for classification upon the training data (with the specified value for\n",
    "    # C, epsilon and the kernel function), and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def support_vector_machine_without_kernel(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        C=1,\n",
    "        tol=1e-3,\n",
    "        max_iter=1000,\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\"max_iter\": [1000, 2000], \"tol\": [1e-3, 1e-4], \"C\": [1, 10, 100]}\n",
    "            ]\n",
    "            svm = GridSearchCV(LinearSVC(), tuned_parameters, cv=5, scoring=\"accuracy\")\n",
    "        else:\n",
    "            svm = LinearSVC(C=C, tol=tol, max_iter=max_iter)\n",
    "\n",
    "        # Fit the model\n",
    "        svm.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(svm.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            svm = svm.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "\n",
    "        distance_training_platt = 1 / (1 + np.exp(svm.decision_function(train_X)))\n",
    "        pred_prob_training_y = (\n",
    "            distance_training_platt / distance_training_platt.sum(axis=1)[:, None]\n",
    "        )\n",
    "        distance_test_platt = 1 / (1 + np.exp(svm.decision_function(test_X)))\n",
    "        pred_prob_test_y = (\n",
    "            distance_test_platt / distance_test_platt.sum(axis=1)[:, None]\n",
    "        )\n",
    "        pred_training_y = svm.predict(train_X)\n",
    "        pred_test_y = svm.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=svm.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=svm.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a nearest neighbor approach for classification upon the training data (with the specified value for\n",
    "    # k), and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def k_nearest_neighbor(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        n_neighbors=5,\n",
    "        gridsearch=True,\n",
    "        print_model_details=False,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [{\"n_neighbors\": [1, 2, 5, 10]}]\n",
    "            knn = GridSearchCV(\n",
    "                KNeighborsClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "        # Fit the model\n",
    "        knn.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(knn.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            knn = knn.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = knn.predict_proba(train_X)\n",
    "        pred_prob_test_y = knn.predict_proba(test_X)\n",
    "        pred_training_y = knn.predict(train_X)\n",
    "        pred_test_y = knn.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=knn.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=knn.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a decision tree approach for classification upon the training data (with the specified value for\n",
    "    # the minimum samples in the leaf, and the export path and files if print_model_details=True)\n",
    "    # and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def decision_tree(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        min_samples_leaf=50,\n",
    "        criterion=\"gini\",\n",
    "        print_model_details=False,\n",
    "        export_tree_path=\"Example_graphs/Chapter7/\",\n",
    "        export_tree_name=\"tree.dot\",\n",
    "        gridsearch=True,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"min_samples_leaf\": [2, 10, 50, 100, 200],\n",
    "                    \"criterion\": [\"gini\", \"entropy\"],\n",
    "                }\n",
    "            ]\n",
    "            dtree = GridSearchCV(\n",
    "                DecisionTreeClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            dtree = DecisionTreeClassifier(\n",
    "                min_samples_leaf=min_samples_leaf, criterion=criterion\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "\n",
    "        dtree.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(dtree.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            dtree = dtree.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = dtree.predict_proba(train_X)\n",
    "        pred_prob_test_y = dtree.predict_proba(test_X)\n",
    "        pred_training_y = dtree.predict(train_X)\n",
    "        pred_test_y = dtree.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(\n",
    "            pred_prob_training_y, columns=dtree.classes_\n",
    "        )\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=dtree.classes_)\n",
    "\n",
    "        if print_model_details:\n",
    "            ordered_indices = [\n",
    "                i[0]\n",
    "                for i in sorted(\n",
    "                    enumerate(dtree.feature_importances_),\n",
    "                    key=lambda x: x[1],\n",
    "                    reverse=True,\n",
    "                )\n",
    "            ]\n",
    "            print(\"Feature importance decision tree:\")\n",
    "            for i in range(0, len(dtree.feature_importances_)):\n",
    "                print(\n",
    "                    train_X.columns[ordered_indices[i]],\n",
    "                )\n",
    "                print(\n",
    "                    \" & \",\n",
    "                )\n",
    "                print(dtree.feature_importances_[ordered_indices[i]])\n",
    "            tree.export_graphviz(\n",
    "                dtree,\n",
    "                out_file=export_tree_path + export_tree_name,\n",
    "                feature_names=train_X.columns,\n",
    "                class_names=dtree.classes_,\n",
    "            )\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a naive bayes approach for classification upon the training data\n",
    "    # and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def naive_bayes(self, train_X, train_y, test_X):\n",
    "        # Create the model\n",
    "        nb = GaussianNB()\n",
    "\n",
    "        # Fit the model\n",
    "        nb.fit(train_X, train_y)\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = nb.predict_proba(train_X)\n",
    "        pred_prob_test_y = nb.predict_proba(test_X)\n",
    "        pred_training_y = nb.predict(train_X)\n",
    "        pred_test_y = nb.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=nb.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=nb.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "    # Apply a random forest approach for classification upon the training data (with the specified value for\n",
    "    # the minimum samples in the leaf, the number of trees, and if we should print some of the details of the\n",
    "    # model print_model_details=True) and use the created model to predict the outcome for both the\n",
    "    # test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "    # probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "    def random_forest(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        n_estimators=10,\n",
    "        min_samples_leaf=5,\n",
    "        criterion=\"gini\",\n",
    "        print_model_details=False,\n",
    "        gridsearch=True,\n",
    "    ):\n",
    "\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"min_samples_leaf\": [2, 10, 50, 100, 200],\n",
    "                    \"n_estimators\": [10, 50, 100],\n",
    "                    \"criterion\": [\"gini\", \"entropy\"],\n",
    "                }\n",
    "            ]\n",
    "            rf = GridSearchCV(\n",
    "                RandomForestClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                criterion=criterion,\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "\n",
    "        rf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(rf.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            rf = rf.best_estimator_\n",
    "\n",
    "        pred_prob_training_y = rf.predict_proba(train_X)\n",
    "        pred_prob_test_y = rf.predict_proba(test_X)\n",
    "        pred_training_y = rf.predict(train_X)\n",
    "        pred_test_y = rf.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=rf.classes_)\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=rf.classes_)\n",
    "\n",
    "        if print_model_details:\n",
    "            ordered_indices = [\n",
    "                i[0]\n",
    "                for i in sorted(\n",
    "                    enumerate(rf.feature_importances_), key=lambda x: x[1], reverse=True\n",
    "                )\n",
    "            ]\n",
    "            print(\"Feature importance random forest:\")\n",
    "            for i in range(0, len(rf.feature_importances_)):\n",
    "                print(\n",
    "                    train_X.columns[ordered_indices[i]],\n",
    "                )\n",
    "                print(\n",
    "                    \" & \",\n",
    "                )\n",
    "                print(rf.feature_importances_[ordered_indices[i]])\n",
    "\n",
    "        return (\n",
    "            pred_training_y,\n",
    "            pred_test_y,\n",
    "            frame_prob_training_y,\n",
    "            frame_prob_test_y,\n",
    "        )\n",
    "\n",
    "# Class to abstract a history of numerical values we can use as an attribute.\n",
    "class NumericalAbstraction:\n",
    "\n",
    "    # For the slope we need a bit more work.\n",
    "    # We create time points, assuming discrete time steps with fixed delta t:\n",
    "    def get_slope(self, data):\n",
    "        \n",
    "        times = np.array(range(0, len(data.index)))\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "        # Check for NaN's\n",
    "        mask = ~np.isnan(data)\n",
    "\n",
    "        # If we have no data but NaN we return NaN.\n",
    "        if (len(data[mask]) == 0):\n",
    "            return np.nan\n",
    "        # Otherwise we return the slope.\n",
    "        else:\n",
    "            slope, _, _, _, _ = stats.linregress(times[mask], data[mask])\n",
    "            return slope\n",
    "\n",
    "    #TODO Add your own aggregation function here:\n",
    "    # def my_aggregation_function(self, data) \n",
    "\n",
    "    # This function aggregates a list of values using the specified aggregation\n",
    "    # function (which can be 'mean', 'max', 'min', 'median', 'std', 'slope')\n",
    "    def aggregate_value(self,data, window_size, aggregation_function):\n",
    "        window = str(window_size) + 's'\n",
    "        # Compute the values and return the result.\n",
    "        if aggregation_function == 'mean':\n",
    "            return data.rolling(window, min_periods=window_size).mean()\n",
    "        elif aggregation_function == 'max':\n",
    "            return data.rolling(window, min_periods=window_size).max()\n",
    "        elif aggregation_function == 'min':\n",
    "            return data.rolling(window, min_periods=window_size).min()\n",
    "        elif aggregation_function == 'median':\n",
    "            return data.rolling(window, min_periods=window_size).median()\n",
    "        elif aggregation_function == 'std':\n",
    "            return data.rolling(window, min_periods=window_size).std()\n",
    "        elif aggregation_function == 'slope':\n",
    "            return data.rolling(window, min_periods=window_size).apply(self.get_slope)\n",
    "        \n",
    "        #TODO: add your own aggregation function here\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "    def abstract_numerical(self, data_table, cols, window_size, aggregation_function_name):\n",
    "    \n",
    "        for col in cols:\n",
    "            \n",
    "            aggregations = self.aggregate_value(data_table[col], window_size, aggregation_function_name)\n",
    "            data_table[col + '_temp_' + aggregation_function_name + '_ws_' + str(window_size)] = aggregations\n",
    "      \n",
    "        \n",
    "        return data_table\n",
    "\n",
    "# Not a class, just a bunch of useful functions.\n",
    "\n",
    "def get_chapter(module_path):\n",
    "    return re.search('_ch._', 'crowdsignals_ch3_outliers.py').group(0).strip('_')\n",
    "\n",
    "def normalize_dataset(data_table, columns):\n",
    "    dt_norm = copy.deepcopy(data_table)\n",
    "    for col in columns:\n",
    "        dt_norm[col] = (data_table[col] - data_table[col].mean()) / (data_table[col].max() - data_table[col].min())\n",
    "    return dt_norm\n",
    "\n",
    "# Calculate the distance between rows.\n",
    "def distance(rows, d_function='euclidean'):\n",
    "    if d_function == 'euclidean':\n",
    "        # Assumes m rows and n columns (attributes), returns and array where each row represents\n",
    "        # the distances to the other rows (except the own row).\n",
    "        return scipy.spatial.distance.pdist(rows, 'euclidean') # todo: replace with numpy?\n",
    "    else:\n",
    "        raise ValueError(\"Unknown distance value '\" + d_function + \"'\")\n",
    "\n",
    "def print_statistics(dataset, describe=True):\n",
    "\n",
    "    if describe:\n",
    "        # .describe() gives number of values, mean, standard deviation, min and max for each column in one table.\n",
    "        print(dataset.describe().round(3).to_string())\n",
    "        return\n",
    "\n",
    "    print('\\ncolumn \\t\\t % missing \\t\\t mean \\t\\t standard deviation \\t\\t min \\t\\t max')\n",
    "    dataset_length = len(dataset.index)\n",
    "    for col in dataset.columns:\n",
    "        print('\\t\\t'.join([f'{col}',\n",
    "                           f'{(dataset_length - dataset[col].count()) / dataset_length * 100:3.1f}%',\n",
    "                           f'{dataset[col].mean():6.3f}',\n",
    "                           f'{dataset[col].std():6.3f}',\n",
    "                           f'{dataset[col].min():6.3f}',\n",
    "                           f'{dataset[col].max():6.3f}']))\n",
    "\n",
    "def print_table_cell(value1, value2):\n",
    "    print(\"{0:.2f}\".format(value1), ' / ', \"{0:.2f}\".format(value2), end='')\n",
    "\n",
    "def print_latex_table_statistics_two_datasets(dataset1, dataset2):\n",
    "    print('attribute, fraction missing values, mean, standard deviation, min, max')\n",
    "    dataset1_length = len(dataset1.index)\n",
    "    dataset2_length = len(dataset2.index)\n",
    "    for col in dataset1.columns:\n",
    "        print(col, '& ', end='')\n",
    "        print_table_cell((float((dataset1_length - dataset1[col].count()))/dataset1_length)*100, (float((dataset2_length - dataset2[col].count()))/dataset2_length)*100)\n",
    "        print(' & ', end='')\n",
    "        print_table_cell(dataset1[col].mean(), dataset2[col].mean())\n",
    "        print(' & ', end='')\n",
    "        print_table_cell(dataset1[col].std(), dataset2[col].std())\n",
    "        print(' & ', end='')\n",
    "        print_table_cell(dataset1[col].min(), dataset2[col].min())\n",
    "        print(' & ', end='')\n",
    "        print_table_cell(dataset1[col].max(), dataset2[col].max())\n",
    "        print('\\\\\\\\')\n",
    "\n",
    "def print_latex_statistics_clusters(dataset, cluster_col, input_cols, label_col):\n",
    "    label_cols = [c for c in dataset.columns if label_col == c[0:len(label_col)]]\n",
    "\n",
    "    clusters = dataset[cluster_col].unique()\n",
    "\n",
    "    for c in input_cols:\n",
    "        print('\\multirow{2}{*}{', c, '} & mean ', end='')\n",
    "        for cluster in clusters:\n",
    "            print(' & ', \"{0:.2f}\".format(dataset.loc[dataset[cluster_col] == cluster, c].mean()), end='')\n",
    "        print('\\\\\\\\')\n",
    "        print(' & std ', end='')\n",
    "        for cluster in clusters:\n",
    "            print(' & ', \"{0:.2f}\".format(dataset.loc[dataset[cluster_col] == cluster, c].std()), end='')\n",
    "        print('\\\\\\\\')\n",
    "\n",
    "    for l in label_cols:\n",
    "        print(l, ' & percentage ', end='')\n",
    "        for cluster in clusters:\n",
    "            print(' & ', \"{0:.2f}\".format((float(dataset.loc[dataset[cluster_col] == cluster, l].sum())/len(dataset[dataset[l] == 1].index) * 100)), '\\%', end='')\n",
    "        print('\\\\\\\\')\n",
    "\n",
    "def print_table_row_performances(row_name, training_len, test_len, values):\n",
    "    scores_over_sd = []\n",
    "    print(row_name, end='')\n",
    "\n",
    "    for val in values:\n",
    "        print(' & ', end='')\n",
    "        sd_train = math.sqrt((val[0]*(1-val[0]))/training_len)\n",
    "        print(\"{0:.4f}\".format(val[0]), end='')\n",
    "        print('\\\\emph{(', \"{0:.4f}\".format(val[0]-2*sd_train), '-', \"{0:.4f}\".format(val[0]+2*sd_train), ')}', ' & ', end='')\n",
    "        sd_test = math.sqrt((val[1]*(1-val[1]))/test_len)\n",
    "        print(\"{0:.4f}\".format(val[1]), end='')\n",
    "        print('\\\\emph{(', \"{0:.4f}\".format(val[1]-2*sd_test), '-', \"{0:.4f}\".format(val[1]+2*sd_test), ')}', end='')\n",
    "        scores_over_sd.append([val[0], sd_train, val[1], sd_test])\n",
    "    print('\\\\\\\\\\\\hline')\n",
    "    return scores_over_sd\n",
    "\n",
    "def print_table_row_performances_regression(row_name, training_len, test_len, values):\n",
    "    print(row_name),\n",
    "\n",
    "    for val in values:\n",
    "        print(' & ', end='')\n",
    "        print(\"{0:.4f}\".format(val[0]), end='')\n",
    "        print('\\\\emph{(', \"{0:.4f}\".format(val[1]), ')}', ' & ', end='')\n",
    "        print(\"{0:.4f}\".format(val[2]), end='')\n",
    "        print('\\\\emph{(', \"{0:.4f}\".format(val[3]), ')}', end='')\n",
    "    print('\\\\\\\\\\\\hline')\n",
    "\n",
    "def print_pearson_correlations(correlations):\n",
    "    for i in range(0, len(correlations)):\n",
    "        if np.isfinite(correlations[i][1]):\n",
    "            print(correlations[i][0], ' & ', \"{0:.4f}\".format(correlations[i][1]), '\\\\\\\\\\\\hline')\n",
    "\n",
    "# This class removes the high frequency data (that might be considered noise) from the data.\n",
    "class LowPassFilter:\n",
    "\n",
    "    def low_pass_filter(self, data_table, col, sampling_frequency, cutoff_frequency, order=5, phase_shift=True):\n",
    "        # http://stackoverflow.com/questions/12093594/how-to-implement-band-pass-butterworth-filter-with-scipy-signal-butter\n",
    "        # Cutoff frequencies are expressed as the fraction of the Nyquist frequency, which is half the sampling frequency\n",
    "        nyq = 0.5 * sampling_frequency\n",
    "        cut = cutoff_frequency / nyq\n",
    "\n",
    "        b, a = butter(order, cut, btype='low', output='ba', analog=False)\n",
    "        if phase_shift:\n",
    "            data_table[col + '_lowpass'] = filtfilt(b, a, data_table[col])\n",
    "        else:\n",
    "            data_table[col + '_lowpass'] = lfilter(b, a, data_table[col])\n",
    "        return data_table\n",
    "\n",
    "# Class for Principal Component Analysis. We can only apply this when we do not have missing values (i.e. NaN).\n",
    "# For this we have to impute these first, be aware of this.\n",
    "class PrincipalComponentAnalysis:\n",
    "\n",
    "    pca = []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pca = []\n",
    "    # Perform the PCA on the selected columns and return the explained variance.\n",
    "    def determine_pc_explained_variance(self, data_table, cols):\n",
    "        # Normalize the data first.\n",
    "        dt_norm = normalize_dataset(data_table, cols)\n",
    "\n",
    "        # perform the PCA.\n",
    "        self.pca = PCA(n_components = len(cols))\n",
    "        self.pca.fit(dt_norm[cols])\n",
    "        # And return the explained variances.\n",
    "        return self.pca.explained_variance_ratio_\n",
    "\n",
    "    # Apply a PCA given the number of components we have selected.\n",
    "    # We add new pca columns.\n",
    "    def apply_pca(self, data_table, cols, number_comp):\n",
    "        # Normalize the data first.\n",
    "        dt_norm = normalize_dataset(data_table, cols)\n",
    "\n",
    "        # perform the PCA.\n",
    "        self.pca = PCA(n_components = number_comp)\n",
    "        self.pca.fit(dt_norm[cols])\n",
    "\n",
    "        # Transform our old values.\n",
    "        new_values = self.pca.transform(dt_norm[cols])\n",
    "\n",
    "        #And add the new ones:\n",
    "        for comp in range(0, number_comp):\n",
    "            data_table['pca_' +str(comp+1)] = new_values[:,comp]\n",
    "\n",
    "        return data_table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_binary_outliers(dataset, col, outlier_col, reset_index):\n",
    "    \"\"\" Plot outliers in case of a binary outlier score. Here, the col specifies the real data\n",
    "    column and outlier_col the columns with a binary value (outlier or not).\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        col (string): Column that you want to plot\n",
    "        outlier_col (string): Outlier column marked with true/false\n",
    "        reset_index (bool): whether to reset the index for plotting\n",
    "    \"\"\"\n",
    "\n",
    "    # Taken from: https://github.com/mhoogen/ML4QS/blob/master/Python3Code/util/VisualizeDataset.py\n",
    "\n",
    "    dataset = dataset.dropna(axis=0, subset=[col, outlier_col])\n",
    "    dataset[outlier_col] = dataset[outlier_col].astype(\"bool\")\n",
    "\n",
    "    if reset_index:\n",
    "        dataset = dataset.reset_index()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.xlabel(\"samples\")\n",
    "    plt.ylabel(\"value\")\n",
    "\n",
    "    # Plot non outliers in default color\n",
    "    ax.plot(\n",
    "        dataset.index[~dataset[outlier_col]],\n",
    "        dataset[col][~dataset[outlier_col]],\n",
    "        \"+\",\n",
    "    )\n",
    "    # Plot data points that are outliers in red\n",
    "    ax.plot(\n",
    "        dataset.index[dataset[outlier_col]],\n",
    "        dataset[col][dataset[outlier_col]],\n",
    "        \"r+\",\n",
    "    )\n",
    "\n",
    "    plt.legend(\n",
    "        [\"outlier \" + col, \"no outlier \" + col],\n",
    "        loc=\"upper center\",\n",
    "        ncol=2,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def mark_outliers_iqr(dataset, col):\n",
    "    \"\"\"Function to mark values as outliers using the IQR method.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        col (string): The column you want apply outlier detection to\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original dataframe with an extra boolean column \n",
    "        indicating whether the value is an outlier or not.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = dataset.copy()\n",
    "\n",
    "    Q1 = dataset[col].quantile(0.25)\n",
    "    Q3 = dataset[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    dataset[col + \"_outlier\"] = (dataset[col] < lower_bound) | (\n",
    "        dataset[col] > upper_bound\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def mark_outliers_chauvenet(dataset, col, C=2):\n",
    "    \"\"\"Finds outliers in the specified column of datatable and adds a binary column with\n",
    "    the same name extended with '_outlier' that expresses the result per data point.\n",
    "    \n",
    "    Taken from: https://github.com/mhoogen/ML4QS/blob/master/Python3Code/Chapter3/OutlierDetection.py\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        col (string): The column you want apply outlier detection to\n",
    "        C (int, optional): Degree of certainty for the identification of outliers given the assumption \n",
    "                           of a normal distribution, typicaly between 1 - 10. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original dataframe with an extra boolean column \n",
    "        indicating whether the value is an outlier or not.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = dataset.copy()\n",
    "    # Compute the mean and standard deviation.\n",
    "    mean = dataset[col].mean()\n",
    "    std = dataset[col].std()\n",
    "    N = len(dataset.index)\n",
    "    criterion = 1.0 / (C * N)\n",
    "\n",
    "    # Consider the deviation for the data points.\n",
    "    deviation = abs(dataset[col] - mean) / std\n",
    "\n",
    "    # Express the upper and lower bounds.\n",
    "    low = -deviation / math.sqrt(C)\n",
    "    high = deviation / math.sqrt(C)\n",
    "    prob = []\n",
    "    mask = []\n",
    "\n",
    "    # Pass all rows in the dataset.\n",
    "    for i in range(0, len(dataset.index)):\n",
    "        # Determine the probability of observing the point\n",
    "        prob.append(\n",
    "            1.0 - 0.5 * (scipy.special.erf(high[i]) - scipy.special.erf(low[i]))\n",
    "        )\n",
    "        # And mark as an outlier when the probability is below our criterion.\n",
    "        mask.append(prob[i] < criterion)\n",
    "    dataset[col + \"_outlier\"] = mask\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def mark_outliers_lof(dataset, columns, n=20):\n",
    "    \"\"\"Mark values as outliers using LOF\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        col (string): The column you want apply outlier detection to\n",
    "        n (int, optional): n_neighbors. Defaults to 20.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The original dataframe with an extra boolean column\n",
    "        indicating whether the value is an outlier or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = dataset.copy()\n",
    "\n",
    "    lof = LocalOutlierFactor(n_neighbors=n)\n",
    "    data = dataset[columns]\n",
    "    outliers = lof.fit_predict(data)\n",
    "    X_scores = lof.negative_outlier_factor_\n",
    "\n",
    "    dataset[\"outlier_lof\"] = outliers == -1\n",
    "    return dataset, outliers, X_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"../data/interim/01_Data_Processed.pkl\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_df=df[df[\"Set\"]==1]\n",
    "plt.plot(set_df[\"Accelerometer_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"Accelerometer_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(set_df[\"Accelerometer_y\"].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_unique=df[\"Label\"].unique()\n",
    "df_label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in df_label_unique:\n",
    "    subset = df[df[\"Label\"]==label]\n",
    "    plt.plot(subset[\"Accelerometer_y\"].reset_index(drop=True),label=label)\n",
    "    plt.title(label=label)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in df_label_unique:\n",
    "    subset = df[df[\"Label\"]==label]\n",
    "    plt.title(label=label)\n",
    "    plt.plot(subset[:100][\"Accelerometer_y\"].reset_index(drop=True),label=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogory_df=df.query(\"Label=='squat'\").query(\"Participants=='A'\").reset_index()\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "catogory_df.groupby([\"Category\"])[\"Accelerometer_y\"].plot()\n",
    "ax.set_ylabel(\"Accelerometer\")\n",
    "ax.set_xlabel(\"samples\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Participants_df=df.query(\"Label=='bench'\").sort_values(\"Participants\").reset_index()\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "Participants_df.groupby([\"Participants\"])[\"Accelerometer_y\"].plot()\n",
    "ax.set_ylabel(\"Accelerometer\")\n",
    "ax.set_xlabel(\"samples\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df[\"Label\"].unique()\n",
    "participants=df[\"Participants\"].unique()\n",
    "\n",
    "for label in labels:\n",
    "    for participant in participants:\n",
    "        all_axis_df=df.query(f\"Label=='{label}'\").query(f\"Participants=='{participant}'\").reset_index()\n",
    "\n",
    "\n",
    "        if len(all_axis_df)!=0:\n",
    "            fig,ax=plt.subplots()\n",
    "            all_axis_df[[\"Accelerometer_x\",\"Accelerometer_y\",\"Accelerometer_z\"]].plot(ax=ax)\n",
    "            ax.set_ylabel(\"Accelerometer\")\n",
    "            ax.set_xlabel(\"samples\")\n",
    "            plt.title(f\"{label}({participant})\".title())\n",
    "            plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df[\"Label\"].unique()\n",
    "participants=df[\"Participants\"].unique()\n",
    "\n",
    "for label in labels:\n",
    "    for participant in participants:\n",
    "        all_axis_df=df.query(f\"Label=='{label}'\").query(f\"Participants=='{participant}'\").reset_index()\n",
    "\n",
    "\n",
    "        if len(all_axis_df)!=0:\n",
    "            fig,ax=plt.subplots()\n",
    "            all_axis_df[[\"Gyroscope_x\",\"Gyroscope_y\",\"Gyroscope_z\"]].plot(ax=ax)\n",
    "            ax.set_ylabel(\"Gyroscope\")\n",
    "            ax.set_xlabel(\"samples\")\n",
    "            plt.title(f\"{label}({participant})\".title())\n",
    "            plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df[\"Label\"].unique()\n",
    "participants=df[\"Participants\"].unique()\n",
    "\n",
    "for label in labels:\n",
    "    for participant in participants:\n",
    "        com_plot_df=df.query(f\"Label=='{label}'\").query(f\"Participants=='{participant}'\").reset_index()\n",
    "\n",
    "\n",
    "        if len(com_plot_df)!=0:\n",
    "\n",
    "            fig,ax=plt.subplots(nrows=2,sharex=True)\n",
    "            com_plot_df[[\"Accelerometer_x\",\"Accelerometer_y\",\"Accelerometer_z\"]].plot(ax=ax[0])\n",
    "            com_plot_df[[\"Gyroscope_x\",\"Gyroscope_y\",\"Gyroscope_z\"]].plot(ax=ax[1])\n",
    "            ax[1].set_xlabel(\"samples\")\n",
    "            ax[0].legend()\n",
    "            ax[1].legend()    \n",
    "            plt.title(f\"{label.title()}({participant})\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_col=list(df.columns[:6])\n",
    "df[outlier_col[:3]+[\"Label\"]].boxplot(by=\"Label\",figsize=(20,10),layout=(1,3))\n",
    "df[outlier_col[3:6]+[\"Label\"]].boxplot(by=\"Label\",figsize=(20,10),layout=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in outlier_col:\n",
    "    dataset=mark_outliers_iqr(df,col)\n",
    "    plot_binary_outliers(dataset,col,col+\"_outlier\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[outlier_col[:3]+[\"Label\"]].plot.hist(by=\"Label\",figsize=(20,10),layout=(3,3))\n",
    "df[outlier_col[3:6]+[\"Label\"]].plot.hist(by=\"Label\",figsize=(20,10),layout=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in outlier_col:\n",
    "    dataset=mark_outliers_chauvenet(df,col)\n",
    "    plot_binary_outliers(dataset,col,col+\"_outlier\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,out,x=mark_outliers_lof(df,outlier_col)\n",
    "\n",
    "for col in outlier_col:\n",
    "    plot_binary_outliers(dataset,col,\"outlier_lof\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=\"bench\"\n",
    "for col in outlier_col:\n",
    "    dataset=mark_outliers_iqr(df[df[\"Label\"]==label],col)\n",
    "    plot_binary_outliers(dataset,col,col+\"_outlier\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=\"bench\"\n",
    "for col in outlier_col:\n",
    "    dataset=mark_outliers_chauvenet(df[df[\"Label\"]==label],col)\n",
    "    plot_binary_outliers(dataset,col,col+\"_outlier\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,out,x=mark_outliers_lof(df[df[\"Label\"]==label],outlier_col)\n",
    "\n",
    "for col in outlier_col:\n",
    "    plot_binary_outliers(dataset,col,\"outlier_lof\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_removed_df=df.copy()\n",
    "for col in outlier_col:\n",
    "    for label in df[\"Label\"].unique():\n",
    "        dataset=mark_outliers_chauvenet(df[df[\"Label\"]==label],col)\n",
    "        dataset.loc[dataset[col + \"_outlier\"],col]= np.nan\n",
    "        outlier_removed_df.loc[(outlier_removed_df[\"Label\"]==label),col]=dataset[col]\n",
    "        n_outliers=len(df) - len(outlier_removed_df[col].dropna())\n",
    "        print(f\"Removed {n_outliers} from {col} for {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_removed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=outlier_removed_df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pridictor_col=list(df.columns[:6])\n",
    "for col in pridictor_col:\n",
    "    df[col] = df[col].interpolate()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=df[df[\"Set\"]==1].index[-1] - df[df[\"Set\"]==1].index[0]\n",
    "duration.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in df[\"Set\"].unique():\n",
    "    duration=df[df[\"Set\"]==s].index[-1] - df[df[\"Set\"]==s].index[0]\n",
    "    df.loc[(df[\"Set\"]==s),\"Duration\"]=duration.seconds\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_df=df.groupby([\"Category\"])[\"Duration\"].mean()\n",
    "duration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lowpass=df.copy()\n",
    "\n",
    "LowPass=LowPassFilter()\n",
    "fs=1000/200\n",
    "cutoff=1.2\n",
    "\n",
    "\n",
    "df_lowpass=LowPass.low_pass_filter(df_lowpass,\"Accelerometer_y\",fs,cutoff,order=5)\n",
    "subset=df_lowpass[df_lowpass[\"Set\"]==45]\n",
    "fig,ax=plt.subplots(nrows=2,sharex=True,figsize=(20,10))\n",
    "ax[0].plot(subset[\"Accelerometer_y\"].reset_index(drop=True),label=\"raw data\")\n",
    "ax[1].plot(subset[\"Accelerometer_y_lowpass\"].reset_index(drop=True),label=\"butterworth data\") \n",
    "ax[0].legend(loc=\"upper center\",bbox_to_anchor=(0.5,1.15),fancybox=True,shadow=True)\n",
    "ax[1].legend(loc=\"upper center\",bbox_to_anchor=(0.5,1.15),fancybox=True,shadow=True)  \n",
    "\n",
    "\n",
    "# Make smooth graph at all col\n",
    "for col in pridictor_col:\n",
    "    df_lowpass=LowPass.low_pass_filter(df_lowpass,col,fs,cutoff)\n",
    "    df_lowpass[col]=df_lowpass[col+\"_lowpass\"]\n",
    "    del df_lowpass[col+\"_lowpass\"]\n",
    "\n",
    "df_lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca=df_lowpass.copy()\n",
    "PCA1=PrincipalComponentAnalysis()\n",
    "pc_values1=PCA1.determine_pc_explained_variance(df_pca,pridictor_col)\n",
    "df_pca=PCA1.apply_pca(df_pca,pridictor_col,3)\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=df_pca[df_pca[\"Set\"]==35]\n",
    "subset[[\"pca_1\",\"pca_2\",\"pca_3\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squared=df_pca.copy()\n",
    "acc_r=df_squared[\"Accelerometer_x\"]**2+df_squared[\"Accelerometer_y\"]**2+df_squared[\"Accelerometer_z\"]**2\n",
    "gyro_r=df_squared[\"Gyroscope_x\"]**2+df_squared[\"Gyroscope_y\"]**2+df_squared[\"Gyroscope_z\"]**2\n",
    "df_squared[\"Accelerometer_r\"]=np.sqrt(acc_r)\n",
    "df_squared[\"Gyroscope_r\"]=np.sqrt(gyro_r)\n",
    "df_squared=df_squared.drop(columns=[\"Duration\"])\n",
    "df_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=df_squared[df_squared[\"Set\"]==18]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=df_squared[df_squared[\"Set\"]==14]\n",
    "subset[[\"Accelerometer_r\",\"Gyroscope_r\"]].plot()\n",
    "subset[[\"Accelerometer_r\",\"Gyroscope_r\"]].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal=df_squared.copy()\n",
    "df_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal=df_squared.copy()\n",
    "NumAbs=NumericalAbstraction()\n",
    "\n",
    "pridictor_col=pridictor_col+[\"Accelerometer_r\",\"Gyroscope_r\"]\n",
    "\n",
    "ws=int(1000/200)\n",
    "for col in pridictor_col:\n",
    "    df_temporal=NumAbs.abstract_numerical(df_temporal,[col],ws,\"mean\")\n",
    "    df_temporal=NumAbs.abstract_numerical(df_temporal,[col],ws,\"std\")\n",
    "df_temporal_list=[]\n",
    "for s in df_temporal[\"Set\"].unique():\n",
    "    subset=df_temporal[df_temporal[\"Set\"]==s].copy()\n",
    "    for col in pridictor_col:\n",
    "        subset=NumAbs.abstract_numerical(subset,[col],ws,\"mean\")\n",
    "        subset=NumAbs.abstract_numerical(subset,[col],ws,\"std\")\n",
    "    df_temporal_list.append(subset)\n",
    "\n",
    "df_temporal=pd.concat(df_temporal_list)\n",
    "\n",
    "df_temporal.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[[\"Gyroscope_y\",\"Gyroscope_y_temp_mean_ws_5\",\"Gyroscope_y_temp_std_ws_5\"]].plot()\n",
    "subset[[\"Accelerometer_y\",\"Accelerometer_y_temp_mean_ws_5\",\"Accelerometer_y_temp_std_ws_5\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frq=df_temporal.copy().reset_index()\n",
    "df_frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrqAbs=FourierTransformation()\n",
    "\n",
    "fs= int(1000/200)\n",
    "ws=int(2800/200)\n",
    "\n",
    "\n",
    "df_frq_list=[]\n",
    "for s in df_frq[\"Set\"].unique():\n",
    "    subset=df_frq[df_frq[\"Set\"]==s].reset_index(drop=True).copy()\n",
    "    subset=FrqAbs.abstract_frequency(subset,pridictor_col,ws,fs)\n",
    "    df_frq_list.append(subset)\n",
    "\n",
    "df_frq=pd.concat(df_frq_list).set_index(\"epoch (ms)\",drop=True)\n",
    "df_frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frq=df_frq.dropna()\n",
    "df_frq=df_frq.iloc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster=df_frq.copy()\n",
    "cluster_col=[\"Accelerometer_x\",\"Accelerometer_y\",\"Accelerometer_z\"]\n",
    "k_values=range(2,10)\n",
    "inertias=[]\n",
    "\n",
    "for k in k_values:\n",
    "    subset=df_cluster[cluster_col]\n",
    "    kmeans=KMeans(n_clusters=k,n_init=20,random_state=0)\n",
    "    cluster_label=kmeans.fit_predict(subset)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(k_values,inertias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=5,n_init=20,random_state=0)\n",
    "subset=df_cluster[cluster_col]\n",
    "df_cluster[\"Cluster\"]=kmeans.fit_predict(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,15))\n",
    "ax=fig.add_subplot(projection=\"3d\")\n",
    "for c in df_cluster[\"Cluster\"].unique():\n",
    "    subset=df_cluster[df_cluster[\"Cluster\"]==c]\n",
    "    ax.scatter(subset[\"Accelerometer_x\"],subset[\"Accelerometer_y\"],subset[\"Accelerometer_z\"],label=c)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,15))\n",
    "ax=fig.add_subplot(projection=\"3d\")\n",
    "for i in df_cluster[\"Label\"].unique():\n",
    "    subset=df_cluster[df_cluster[\"Label\"]==i]\n",
    "    ax.scatter(subset[\"Accelerometer_x\"],subset[\"Accelerometer_y\"],subset[\"Accelerometer_z\"],label=c)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_cluster\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.drop([\"Participants\",\"Category\",\"Set\"],axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train.drop(\"Label\",axis=1)\n",
    "y=df_train[\"Label\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.25,stratify=y)\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_col=[\"Accelerometer_x\",\"Accelerometer_y\",\"Accelerometer_z\",\"Gyroscope_x\",\"Gyroscope_y\",\"Gyroscope_z\"]\n",
    "square_col=[\"Accelerometer_r\",\"Gyroscope_r\"]\n",
    "pca_col=[\"pca_1\",\"pca_2\",\"pca_3\"]\n",
    "time_col=[f for f in df_train.columns if \"_temp_\" in f]\n",
    "freq_col=[f for f in df_train.columns if (\"_freq\" in f) or (\"_pse\" in f)]\n",
    "cluster_col=[\"Cluster\"]\n",
    "print(len(basic_col))\n",
    "print(len(square_col))\n",
    "print(len(pca_col))\n",
    "print(len(time_col))\n",
    "print(len(freq_col))\n",
    "print(len(cluster_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_set_1=list(set(basic_col))\n",
    "f_set_2=list(set(basic_col+square_col+pca_col))\n",
    "f_set_3=list(set(f_set_2+time_col))\n",
    "f_set_4=list(set(f_set_3+freq_col+cluster_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=ClassificationAlgorithms()\n",
    "selected_col,ordered_col,orederd_scores=learner.forward_selection(10,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orederd_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterations=1\n",
    "score_df=pd.DataFrame()\n",
    "possible_feature_sets=[\n",
    "    f_set_1,f_set_2,f_set_3,f_set_4,selected_col\n",
    "]\n",
    "feature_names=[\n",
    "    \"f_col_1\",\n",
    "    \"f_col_2\",\n",
    "    \"f_col_3\",\n",
    "    \"f_col_4\",\n",
    "    \"selected_col\",\n",
    "]\n",
    "for i, f in zip(range(len(possible_feature_sets)), feature_names):\n",
    "    print(\"Feature set:\", i)\n",
    "    selected_train_X = X_train[possible_feature_sets[i]]\n",
    "    selected_test_X = X_test[possible_feature_sets[i]]\n",
    "\n",
    "    # First run non deterministic classifiers to average their score.\n",
    "    performance_test_nn = 0\n",
    "    performance_test_rf = 0\n",
    "\n",
    "    for it in range(0, iterations):\n",
    "        print(\"\\tTraining neural network,\", it)\n",
    "        (\n",
    "            class_train_y,\n",
    "            class_test_y,\n",
    "            class_train_prob_y,\n",
    "            class_test_prob_y,\n",
    "        ) = learner.feedforward_neural_network(\n",
    "            selected_train_X,\n",
    "            y_train,\n",
    "            selected_test_X,\n",
    "            gridsearch=False,\n",
    "        )\n",
    "        performance_test_nn += accuracy_score(y_test, class_test_y)\n",
    "\n",
    "        print(\"\\tTraining random forest,\", it)\n",
    "        (\n",
    "            class_train_y,\n",
    "            class_test_y,\n",
    "            class_train_prob_y,\n",
    "            class_test_prob_y,\n",
    "        ) = learner.random_forest(\n",
    "            selected_train_X, y_train, selected_test_X, gridsearch=True\n",
    "        )\n",
    "        performance_test_rf += accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    performance_test_nn = performance_test_nn / iterations\n",
    "    performance_test_rf = performance_test_rf / iterations\n",
    "\n",
    "    # And we run our deterministic classifiers:\n",
    "    print(\"\\tTraining KNN\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.k_nearest_neighbor(\n",
    "        selected_train_X, y_train, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    performance_test_knn = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    print(\"\\tTraining decision tree\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.decision_tree(\n",
    "        selected_train_X, y_train, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    performance_test_dt = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    print(\"\\tTraining naive bayes\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.naive_bayes(selected_train_X, y_train, selected_test_X)\n",
    "\n",
    "    performance_test_nb = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    # Save results to dataframe\n",
    "    models = [\"NN\", \"RF\", \"KNN\", \"DT\", \"NB\"]\n",
    "    new_scores = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": models,\n",
    "            \"feature_set\": f,\n",
    "            \"accuracy\": [\n",
    "                performance_test_nn,\n",
    "                performance_test_rf,\n",
    "                performance_test_knn,\n",
    "                performance_test_dt,\n",
    "                performance_test_nb,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    score_df = pd.concat([score_df, new_scores])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list=score_df.sort_values(by=\"accuracy\",ascending=False).head()\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train_y,class_test_y,class_train_prob_y,class_test_prob_y=learner.random_forest(\n",
    "    X_train[f_set_4],y_train,X_test[f_set_4],gridsearch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_test,class_test_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=class_test_prob_y.columns\n",
    "cm=confusion_matrix(y_test,class_test_y,labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j]),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df=df.drop([\"Set\",\"Category\"],axis=1)\n",
    "X_train=participant_df[participant_df[\"Participants\"] !=\"A\"].drop([\"Label\"],axis=1)\n",
    "y_train=participant_df[participant_df[\"Participants\"] !=\"A\"][\"Label\"]\n",
    "\n",
    "X_test=participant_df[participant_df[\"Participants\"] !=\"A\"].drop([\"Label\"],axis=1)\n",
    "y_test=participant_df[participant_df[\"Participants\"] !=\"A\"][\"Label\"]\n",
    "\n",
    "X_train=X_train.drop([\"Participants\"],axis=1)\n",
    "X_test=X_test.drop([\"Participants\"],axis=1)\n",
    "\n",
    "\n",
    "class_train_y,class_test_y,class_train_prob_y,class_test_prob_y=learner.random_forest(\n",
    "    X_train[f_set_4],y_train,X_test[f_set_4],gridsearch=True\n",
    ")\n",
    "\n",
    "classes=class_test_prob_y.columns\n",
    "cm=confusion_matrix(y_test,class_test_y,labels=classes)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j]),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_test,class_test_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_train_y,class_test_y,class_train_prob_y,class_test_prob_y=learner.feedforward_neural_network(\n",
    "    X_train[selected_col],y_train,X_test[selected_col],gridsearch=False\n",
    ")\n",
    "\n",
    "classes=class_test_prob_y.columns\n",
    "cm=confusion_matrix(y_test,class_test_y,labels=classes)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j]),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_test,class_test_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"../data/interim/01_Data_Processed.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df[\"Label\"]!=\"rest\"]\n",
    "acc_r=df[\"Accelerometer_x\"]**2+df[\"Accelerometer_y\"]**2+df[\"Accelerometer_z\"]**2\n",
    "gyro_r=df[\"Gyroscope_x\"]**2+df[\"Gyroscope_y\"]**2+df[\"Gyroscope_z\"]**2\n",
    "df[\"Accelerometer_r\"]=np.sqrt(acc_r)\n",
    "df[\"Gyroscope_r\"]=np.sqrt(gyro_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_df=df[df[\"Label\"]==\"bench\"]\n",
    "squat_df=df[df[\"Label\"]==\"squat\"]\n",
    "row_df=df[df[\"Label\"]==\"row\"]\n",
    "ohp_df=df[df[\"Label\"]==\"ohp\"]\n",
    "dead_df=df[df[\"Label\"]==\"dead\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=1000/200\n",
    "LowPass=LowPassFilter()\n",
    "\n",
    "bench_set=bench_df[bench_df[\"Set\"]==bench_df[\"Set\"].unique()[0]]\n",
    "squat_set=squat_df[squat_df[\"Set\"]==squat_df[\"Set\"].unique()[0]]\n",
    "row_set=row_df[row_df[\"Set\"]==row_df[\"Set\"].unique()[0]]\n",
    "ohp_set=ohp_df[ohp_df[\"Set\"]==ohp_df[\"Set\"].unique()[0]]\n",
    "dead_set=dead_df[dead_df[\"Set\"]==dead_df[\"Set\"].unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=\"Accelerometer_y\"\n",
    "LowPass.low_pass_filter(bench_set,column,fs,0.4,10)[column+\"_lowpass\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(bench_set,cutoff=0.4)\n",
    "count(squat_set,cutoff=0.35)\n",
    "count(row_set,cutoff=0.65,column=\"Gyroscope_x\")\n",
    "count(ohp_set,cutoff=0.35)\n",
    "count(dead_set,cutoff=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Reps\"]=df[\"Category\"].apply(lambda x:5 if x == \"heavy\" else 10)\n",
    "rep_df=df.groupby([\"Label\",\"Category\",\"Set\"])[\"Reps\"].max().reset_index()\n",
    "rep_df[\"Reps_pred\"]=0\n",
    "\n",
    "for s in df[\"Set\"].unique():\n",
    "    subset=df[df[\"Set\"]==s]\n",
    "    column=\"Accelerometer_r\"\n",
    "    cutoff=0.4\n",
    "    if subset[\"Label\"].iloc[0] ==\"squat\":\n",
    "        cutoff=0.35\n",
    "    if subset[\"Label\"].iloc[0] ==\"row\":\n",
    "        cutoff=0.65\n",
    "    if subset[\"Label\"].iloc[0] ==\"ohp\":\n",
    "        cutoff=0.35\n",
    "\n",
    "    reps=count(subset,cutoff,10,column)\n",
    "    rep_df.loc[rep_df[\"Set\"]==s,\"Reps_pred\"]=reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=mean_absolute_error(rep_df[\"Reps\"],rep_df[\"Reps_pred\"]).round(2)\n",
    "print(error)\n",
    "rep_df.groupby([\"Label\",\"Category\"])[[\"Reps\",\"Reps_pred\"]].mean().plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
